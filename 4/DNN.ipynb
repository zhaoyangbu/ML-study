{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From <ipython-input-1-76e85090a5ec>:7: read_data_sets (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:297: _maybe_download (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:299: _extract_images (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:304: _extract_labels (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:112: _dense_to_one_hot (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:328: _DataSet.__init__ (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n",
      "Epoch: 0001 cost= 0.069758788\n",
      "Epoch: 0002 cost= 0.053840540\n",
      "Epoch: 0003 cost= 0.043388795\n",
      "Epoch: 0004 cost= 0.039869335\n",
      "Epoch: 0005 cost= 0.036865026\n",
      "Epoch: 0006 cost= 0.034497868\n",
      "Epoch: 0007 cost= 0.032689556\n",
      "Epoch: 0008 cost= 0.033882115\n",
      "Epoch: 0009 cost= 0.031799544\n",
      "Epoch: 0010 cost= 0.031716760\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 10\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "  \n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "  \n",
    "n_hidden_1=128\n",
    "n_hidden_2=64\n",
    "n_hidden_3=12\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([784, n_hidden_1])), \n",
    "    'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])), \n",
    "    'encoder_h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),  \n",
    "    'decoder_h1': tf.Variable(tf.random_normal([n_hidden_3, n_hidden_2])), \n",
    "    'decoder_h2': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])), \n",
    "    'decoder_h3': tf.Variable(tf.random_normal([n_hidden_1, 784])),\n",
    "} \n",
    "biases = { \n",
    "    'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])), \n",
    "    'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'encoder_b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([n_hidden_2])), \n",
    "    'decoder_b2': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'decoder_b3': tf.Variable(tf.random_normal([784])), \n",
    "} \n",
    "   \n",
    "def autoencoder(input):\n",
    "    layer_1=tf.nn.sigmoid(tf.add(tf.matmul(input, weights['encoder_h1']),biases['encoder_b1'])) \n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),biases['encoder_b2'])) \n",
    "    layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['encoder_h3']),biases['encoder_b3']))\n",
    "    return layer_3 \n",
    "\n",
    "def decoder(x): \n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),biases['decoder_b1'])) \n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),biases['decoder_b2']))\n",
    "    layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['decoder_h3']),biases['decoder_b3']))\n",
    "    return layer_3 \n",
    "\n",
    "autoencoder=autoencoder(x) \n",
    "decoder=decoder(autoencoder) \n",
    "prediction=decoder\n",
    "\n",
    "loss=tf.reduce_mean(tf.pow(x-prediction, 2))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    for epoch in range(training_epochs):\n",
    "        for i in range(total_batch): \n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _, c = sess.run([train_step, loss], feed_dict={x: batch_x})\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c)) \n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
